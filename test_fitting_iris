import sys
sys.path.append('/Users/davidasselalou/Desktop/new/')

import numpy as np
import pandas as pd

import tensorflow as tf
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential

from tensorflow.keras.utils import get_custom_objects
from newton_optimizer import NewtonOptimizer

get_custom_objects().update({'NewtonOptimizer': NewtonOptimizer})


from tensorflow.keras.initializers import RandomNormal

file_path = '/Users/davidasselalou/Desktop/Applied_DL_routine/iris.csv'
data = pd.read_csv(file_path)

# Prepare Data
X = data.iloc[:, 0:4].values
y = data.iloc[:, 4].values
encoder = LabelEncoder()
encoder.fit(y)
encoded_Y = encoder.transform(y)
dummy_y = to_categorical(encoded_Y)

# Split Data
X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.2, random_state=42)

class StoreWeightNormCallback(tf.keras.callbacks.Callback):
    def __init__(self):
        super(StoreWeightNormCallback, self).__init__()
        self.weight_norms_per_epoch = []

    def on_epoch_end(self, epoch, logs=None):
        weights = self.model.get_weights()
        weight_norms = [np.linalg.norm(w) for w in weights]
        self.weight_norms_per_epoch.append(weight_norms)
        print(f"Epoch {epoch + 1}, Weight norms: {weight_norms}")



model = Sequential()
model.add(Dense(15, activation='tanh', input_shape=(4,), kernel_initializer=RandomNormal()))  # Dense-Schicht mit 10 Neuronen
model.add(Dense(10, activation='tanh', kernel_initializer=RandomNormal()))  # Dense-Schicht mit 10 Neuronen
model.add(Dense(3, activation='softmax', kernel_initializer=RandomNormal()))  # Output-Schicht mit 1 Neuron (lineare Aktivierung)

        # self.dense = Dense(15, activation='tanh', input_shape=(4,), kernel_initializer=RandomNormal())
        # self.dense1 = Dense(10, activation='tanh', kernel_initializer=RandomNormal())
        # self.output_layer = Dense(3, activation='softmax', kernel_initializer=RandomNormal())

optimizer = NewtonOptimizer()
optimizer.initialize_weights(model)

model.compile(optimizer='NewtonOptimizer', loss='categorical_crossentropy', metrics=['accuracy'])

# Training Parameters
batch_size = X_train.shape[0]

callback = StoreWeightNormCallback()

history = model.fit(X_train, y_train, batch_size=batch_size, epochs=8, callbacks=[callback])


# After training, access the stored weight norms
epoch_weight_norms = callback.weight_norms_per_epoch

# You can now print or analyze epoch_weight_norms
print(epoch_weight_norms)

# Evaluate the model
scores = model.evaluate(X_test, y_test, batch_size=batch_size, verbose="auto")
print(f"Accuracy: {scores[1]*100}")

# Plot Loss-Verlauf
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()






















# # Dummy-Daten erstellen
# np.random.seed(42)
# X_train = np.random.rand(100, 5)  # 100 Datenpunkte mit 5 Features
# y_train = np.random.rand(100, 1)  # Zugeh√∂rige Zielwerte

# # Ein einfaches Sequential-Modell erstellen
# model = Sequential()
# model.add(Dense(10, input_shape=(5,), activation='tanh'))  # Dense-Schicht mit 10 Neuronen
# model.add(Dense(10, activation='tanh'))  # Dense-Schicht mit 10 Neuronen
# model.add(Dense(1, activation='linear'))  # Output-Schicht mit 1 Neuron (lineare Aktivierung)


# # NewtonOptimizer initialisieren und Gewichte des Modells setzen
# optimizer = NewtonOptimizer()
# optimizer.initialize_weights(model)

# # Model kompilieren
# model.compile(optimizer='NewtonOptimizer', loss='mse')

# class StoreWeightNormCallback(tf.keras.callbacks.Callback):
#     def __init__(self):
#         super(StoreWeightNormCallback, self).__init__()
#         self.weight_norms_per_epoch = []

#     def on_epoch_end(self, epoch, logs=None):
#         weights = self.model.get_weights()
#         weight_norms = [np.linalg.norm(w) for w in weights]
#         self.weight_norms_per_epoch.append(weight_norms)
#         print(f"Epoch {epoch + 1}, Weight norms: {weight_norms}")
        
# # Modell trainieren
# callback = StoreWeightNormCallback()

# history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.2, callbacks=[callback])



# # plt.hist(y_train, bins=20)
# # plt.xlabel('y_train')
# # plt.ylabel('Frequency')
# # plt.title('Histogram of y_train')
# # plt.show()

